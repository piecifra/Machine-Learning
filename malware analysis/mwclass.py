#!/usr/bin/env python3

import os, sys, shutil, random
from collections import defaultdict, Counter
from decimal import *
import argparse


# Instantiate the parser
parser = argparse.ArgumentParser(description='Malware family classification with Naive Bayes Classifier, Dataset: DREBIN')

parser.add_argument('-n', default = 5, type=int, nargs='?',
                    help='Minimum nuber of sample per family')

parser.add_argument('-k', default = 10, type=int, nargs='?',
                    help='Set the number of iteration in the cross fold evaluation process')

parser.add_argument('--feature-vectors-path', default = './drebin/feature_vectors.nosync/', type=str,
                    help='Set path for feature vectors folder')

parser.add_argument('--sha256-family-path', default = './drebin/sha256_family.csv', type=str,
                    help='Set path for sha256_family.csv file')

parser.add_argument('-cm', default = False, action='store_true',
					help='Print confusion matrix of last iteration')

args = parser.parse_args()

SAMPLES_FAMILY_MIN = args.n
K = args.k
FVDR = args.feature_vectors_path
SHAF = args.sha256_family_path

if SAMPLES_FAMILY_MIN == None or K == None:
	parser.error('SAMPLES_FAMILY_MIN or K cannot be None')

dm = defaultdict(list)								#dict[malware_family] = [malware_sha_list] 
file_dataset = {}									#tuple dict
malware_hash_list = []								#malware hash list from sha256_family.csv
hash_to_family_map = {}								#dict with key = hash, value = family
malware_family_dataset = defaultdict(list)			#dict with key = family, value = list of hash			

tj = {}
Pj = {}
Pij = {}
TFj = {}
TFij ={}
docs = {}									

C =[] 
V = []
print()
print('------------------------------------------------------------------------------------------')
print('STARTING LEARINING PROCESS WITH AT LEAST ' + str(SAMPLES_FAMILY_MIN) + ' SAMPLES FOR FAMILY')
print(str(K) + '-fold cross validation')
print('------------------------------------------------------------------------------------------')
print()
print()

print('Processing ' + SHAF)
with open(SHAF, 'r') as f:
	lines = f.readlines()
	for l in lines:
		l = l.split(',')
		dm[l[1].strip('\r\n')].append(l[0])
		hash_to_family_map[l[0]] = l[1].strip('\r\n')

#selecting all malware family with more than 20 samples
dm = {k : dm[k] for k in dm.keys() if len(dm[k]) >= SAMPLES_FAMILY_MIN}

#selecting all family from dm
C = dm.keys()

#List with all malware hash
malware_hash_list = [item for sublist in dm.values() for item in sublist]

#Confusion Matrix initialization
confusion_matrix = {}
for c1 in C:
	for c2 in C:
		confusion_matrix [(c1,c2)] = 0

accuracy = 0
total_malware = len(malware_hash_list)

print('Total malware samples: ' + str(total_malware))
print('Total family classes: ' + str(len(C)))
print()

#Dict with Key = Hash of program, Value = (C, Manifest)
print('Processing feature_vectors.nosync')
for file in malware_hash_list:
	with open(FVDR + file, 'r') as f:
		file_dataset[file] = (hash_to_family_map[file], f.readlines())

#Dict with Key = Family, Value = List of all hash programs that belong to that family
for k in file_dataset.keys():
	malware_family_dataset[file_dataset[k][0]].append(k)

for i in range(K):
	#test set contains 1/K samples

	test_set_start = int(total_malware*i/K)
	test_set_end = int(total_malware*(i+1)/K)

	test_set = malware_hash_list[test_set_start:test_set_end]
	dataset_learning = list(set(malware_hash_list)-set(test_set))

	print('Start learning - Iteration ' + str(i))
	V = list(set([item for sublist in [x[1] for x in file_dataset.values()] for item in sublist]))
	for c in C:
		docs[c] = malware_family_dataset[c]
		tj[c] = len(docs[c])
		Pj[c] = float(tj[c])/len(malware_hash_list)
		TFj[c] = sum([len(file_dataset[x][1]) for x in malware_family_dataset[c]])
		word_in_docsc = Counter([item for sublist in [file_dataset[x][1] for x in docs[c]] for item in sublist])
		for v in V:
			TFij[(v,c)] = word_in_docsc[v]
			Pij[(v,c)] = float(TFij[v,c] + 1)/(TFj[c] + len(V))

	correct = 0
	wrong = 0
	print('Testing with: ' + str(len(test_set)))

	for file in test_set:
		ris = ''
		max = 0
		with open(FVDR + file, 'r') as f:
			lines = f.readlines()

		for c in C:
			p = Decimal(Pj[c])
			for v in lines:
				if v in V:
					p = p * Decimal(Pij[(v,c)])
			if p >= max:
				ris = c
				max = p

		if i == 9 and args.__cm == True:
			confusion_matrix[ris, hash_to_family_map[file]] += 1

		if ris == hash_to_family_map[file]:
			correct += 1
		else:
			wrong += 1 


	accuracy_i = float(correct)/(correct+wrong)
	accuracy += accuracy_i
	print('correct: ' + str(correct))
	print('wrong: ' + str(wrong))
	print('accuracy: ' + str(100*accuracy_i) + '%')
	print()

accuracy = float(accuracy)/K
print('Accuracy from ' + str(K) + '-Fold Cross validation: ' + str(100*accuracy) + '%')

confusion_matrix_array = []

#x->c2->correct
#y->c1->ris
for c1 in C:
	l = []
	for c2 in C:
		l.append(confusion_matrix[c1,c2])
	confusion_matrix_array.append(l)

if args.__cm == True:
	print('Printing confusion matrix for all Iteration')
	import seaborn as sn
	import pandas as pd
	import matplotlib.pyplot as plt

	df_cm = pd.DataFrame(confusion_matrix_array, index = C, columns = C)
	plt.figure(figsize = (10,7))
	sn.set(font_scale=1.4)#for label size
	sn.heatmap(df_cm, annot=True,annot_kws={"size": 16})# font size
	plt.show()

